'''
Converting to simple Flow Matching (FM) by replacing:
- model class (DDPM -> Flow Matching)
- training objective (epsilon-pred MSE → conditional velocity-field regression)
- sampler (reverse diffusion loop -> ODE integration loop)

Unchanged:
- ScoreNet architecture
- ExponentialMovingAverage
- MNIST transform and dataloader
- train() loop and reporter() callback pattern
- optimizer + scheduler

Flow matching training:
- sample data image x1 ~ q
- sample noise image x0 ~ N(0, I) (in same shape)
- sample continuous time t ~ U[0, 1]
- define interpolation path: xt = (1-t)x0 + t*x1
- define conditional velocity field: x1-x0
- train network u_theta(xt, t) via MSE-loss

Sampling
- samples generated by drawing x0 ~ N(0, I) and integrating learned ODE
  dx/dt = u_theta(x, t) from t=0 to t=1 using a fixed-step midpoint (RK2) method
'''

import torch
import torch.nn as nn
import numpy as np
from torchvision import transforms, utils
from tqdm.auto import tqdm
import matplotlib.pyplot as plt
import os
import time

from utils import FID, inception_score


# This UNET-style prediction model was originally included as part of the Score-based generative modelling tutorial 
# by Yang Song et al: https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing

''' 
remains unchanged, since FM needs a time-conditioned network that maps (xt, t) -> u_theta(xt, t)
'''

class GaussianFourierProjection(nn.Module):
  """Gaussian random features for encoding time steps."""  
  def __init__(self, embed_dim, scale=30.):
    super().__init__()
    # Randomly sample weights during initialization. These weights are fixed 
    # during optimization and are not trainable.
    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)
  def forward(self, x):
    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi
    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)


class Dense(nn.Module):
  """A fully connected layer that reshapes outputs to feature maps."""
  def __init__(self, input_dim, output_dim):
    super().__init__()
    self.dense = nn.Linear(input_dim, output_dim)
  def forward(self, x):
    return self.dense(x)[..., None, None]


class ScoreNet(nn.Module):
  """A time-dependent score-based model built upon U-Net architecture."""

  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):
    """Initialize a time-dependent score-based network.

    Args:
      marginal_prob_std: A function that takes time t and gives the standard
        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).
      channels: The number of channels for feature maps of each resolution.
      embed_dim: The dimensionality of Gaussian random feature embeddings.
    """
    super().__init__()
    # Gaussian random feature embedding layer for time
    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),
         nn.Linear(embed_dim, embed_dim))
    # Encoding layers where the resolution decreases
    self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)
    self.dense1 = Dense(embed_dim, channels[0])
    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])
    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)
    self.dense2 = Dense(embed_dim, channels[1])
    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])
    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)
    self.dense3 = Dense(embed_dim, channels[2])
    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])
    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)
    self.dense4 = Dense(embed_dim, channels[3])
    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])    

    # Decoding layers where the resolution increases
    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)
    self.dense5 = Dense(embed_dim, channels[2])
    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])
    self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)    
    self.dense6 = Dense(embed_dim, channels[1])
    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])
    self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)    
    self.dense7 = Dense(embed_dim, channels[0])
    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])
    self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)
    
    # The swish activation function
    self.act = lambda x: x * torch.sigmoid(x)
    self.marginal_prob_std = marginal_prob_std
  
  def forward(self, x, t): 
    # Obtain the Gaussian random feature embedding for t   
    embed = self.act(self.embed(t))    
    # Encoding path
    h1 = self.conv1(x)    
    ## Incorporate information from t
    h1 += self.dense1(embed)
    ## Group normalization
    h1 = self.gnorm1(h1)
    h1 = self.act(h1)
    h2 = self.conv2(h1)
    h2 += self.dense2(embed)
    h2 = self.gnorm2(h2)
    h2 = self.act(h2)
    h3 = self.conv3(h2)
    h3 += self.dense3(embed)
    h3 = self.gnorm3(h3)
    h3 = self.act(h3)
    h4 = self.conv4(h3)
    h4 += self.dense4(embed)
    h4 = self.gnorm4(h4)
    h4 = self.act(h4)

    # Decoding path
    h = self.tconv4(h4)
    ## Skip connection from the encoding path
    h += self.dense5(embed)
    h = self.tgnorm4(h)
    h = self.act(h)
    h = self.tconv3(torch.cat([h, h3], dim=1))
    h += self.dense6(embed)
    h = self.tgnorm3(h)
    h = self.act(h)
    h = self.tconv2(torch.cat([h, h2], dim=1))
    h += self.dense7(embed)
    h = self.tgnorm2(h)
    h = self.act(h)
    h = self.tconv1(torch.cat([h, h1], dim=1))

    # Normalize output
    h = h / self.marginal_prob_std(t)[:, None, None, None]
    return h


class ExponentialMovingAverage(torch.optim.swa_utils.AveragedModel):
    """Maintains moving averages of model parameters using an exponential decay.
    ``ema_avg = decay * avg_model_param + (1 - decay) * model_param``
    `torch.optim.swa_utils.AveragedModel <https://pytorch.org/docs/stable/optim.html#custom-averaging-strategies>`_
    is used to compute the EMA.
    """

    def __init__(self, model, decay, device="cpu"):
        def ema_avg(avg_model_param, model_param, num_averaged):
            return decay * avg_model_param + (1 - decay) * model_param

        super().__init__(model, device, ema_avg, use_buffers=True)
  


class FlowMatching(nn.Module):

    def __init__(self, network):
        """
        Initialize Flow Matching model
        """
        
        super(FlowMatching, self).__init__()

        # Reshape input into image format before sending it to network model
        self._network = network
        self.network = lambda x, t: self._network(
            x.reshape(-1, 1, 28, 28), t).reshape(-1, 28 * 28)

        self.mse = nn.MSELoss(reduction="mean")

    def loss(self, x1):
        """
        Conditional Flow Matching objective for the linear path:
            x0 ~ N(0, I)
            t ~ U[0, 1]
            xt = (1-t)x0 + t x1
            target velocity u* = x1 - x0
        """
        x1 = x1.reshape(x1.shape[0], -1)

        x0 = torch.randn_like(x1) # x0 ~ N(0, I)
        t = torch.rand((x1.shape[0], ), device = x1.device, dtype=x1.dtype) # sample continuous time t in [0, 1]
        t_vec = t[:, None]
        xt = (1. - t_vec) * x0 + t_vec * x1 # linear conditional path
        u_t = x1 - x0 # target velocity
        u_theta = self.network(xt, t) # predict velocity field

        return self.mse(u_theta, u_t)

    def step(self, x_t: torch.Tensor, t_start: float, t_end: float, vmax: float = 3.0) -> torch.Tensor:
        """
        Midpoint (RK2) step:
        x_{t_end} = x_t + dt * v( x_t + 0.5*dt*v(x_t,t_start), t_mid )
        with dt = t_end - t_start, t_mid = t_start + 0.5*dt

        x_t: (B,1,28,28)
        """
        # Convert scalar times to per-batch tensors
        t_start = torch.tensor(t_start, device=x_t.device, dtype=x_t.dtype).expand(x_t.shape[0])
        t_end   = torch.tensor(t_end,   device=x_t.device, dtype=x_t.dtype).expand(x_t.shape[0])

        dt = (t_end - t_start)[:, None]
        t_mid = t_start + (t_end - t_start) / 2.0

        return x_t + dt * self.network(
            x_t + self.network(x_t, t_start) * dt / 2.0,
            t_mid
        )
    
    @torch.no_grad()
    def sample(self, shape, n_steps=200):
        """
        Sample by integrating from t=0 to t=1 with n_steps midpoint steps

        Parameters
        ----------
        shape: tuple
            Specify shape of sampled output. For MNIST: (nsamples, 28*28)

        Returns
        -------
        torch.tensor
            sampled image            
        """
        x = torch.randn(shape, device=next(self.parameters()).device)

        dt = 1.0 / n_steps
        t = 0.0
        for _ in range(n_steps):
            x = self.step(x, t, t + dt)
            t = t + dt

        return x


def train(model, optimizer, scheduler, dataloader, epochs, device, ema=True, per_epoch_callback=None):

    # Setup progress bar
    total_steps = len(dataloader)*epochs
    progress_bar = tqdm(range(total_steps), desc="Training")

    if ema:
        ema_global_step_counter = 0
        ema_steps = 10
        ema_adjust = dataloader.batch_size * ema_steps / epochs
        ema_decay = 1.0 - 0.995
        ema_alpha = min(1.0, (1.0 - ema_decay) * ema_adjust)
        ema_model = ExponentialMovingAverage(model, device=device, decay=1.0 - ema_alpha)                
    
    time_total = 0
    for epoch in range(epochs):
        time_start = time.time()
        model.train()

        global_step_counter = 0
        for i, (x, _) in enumerate(dataloader):
            x = x.to(device)
            optimizer.zero_grad()
            loss = model.loss(x)
            loss.backward()
            optimizer.step()
            scheduler.step()

            # Update progress bar
            progress_bar.set_postfix(loss=f"⠀{loss.item():12.4f}", epoch=f"{epoch+1}/{epochs}", lr=f"{scheduler.get_last_lr()[0]:.2E}")
            progress_bar.update()

            if ema:
                ema_global_step_counter += 1
                if ema_global_step_counter%ema_steps==0:
                    ema_model.update_parameters(model)      

        time_end = time.time()

        time_total += time_end - time_start            
        
        if per_epoch_callback:
            per_epoch_callback(ema_model.module if ema else model, epoch)

    return time_total / epochs

def reporter(model, epoch):
    model.eval()
    with torch.no_grad():
        nsamples = 10
        samples = model.sample((nsamples, 28 * 28), n_steps=200).cpu()
        samples = samples.view(-1, 1, 28, 28)

        samples = samples.clamp(-1.0, 1.0)
        samples = (samples + 1.0) / 2.0
        samples = samples.clamp(0.0, 1.0)

        grid = utils.make_grid(samples, nrow=nsamples)
        plt.figure(figsize=(10, 2))
        plt.axis("off")
        plt.imshow(transforms.functional.to_pil_image(grid), cmap="gray")
        plt.savefig(f"FM/fm_samples/epoch_{epoch:03d}.png", bbox_inches="tight")
        plt.close()

'''
    A method modified from DDPM file, used to generate images, time them, and save them
'''
@torch.no_grad()
def generate(model, num_samples, run_number):
    time_start = time.time()
    samples = model.sample((num_samples, 28 * 28), n_steps=200).cpu()
    time_end = time.time()

    samples = samples.view(num_samples, 1, 28, 28)

    samples = samples.clamp(-1.0, 1.0)
    samples = (samples + 1.0) / 2.0
    samples = samples.clamp(0.0, 1.0)

    plotted_samples = samples[0:10, :]

    # Plot in grid
    grid = utils.make_grid(plotted_samples, nrow=10)
    plt.figure(figsize=(10, 2))
    plt.axis("off")
    plt.imshow(transforms.functional.to_pil_image(grid), cmap="gray")
    plt.savefig("FM/Generations/{}.png".format(run_number), bbox_inches="tight")
    plt.close()

    return (time_end - time_start) / num_samples, samples

def main(run_number, dataloader, epochs, use_reporter):
    os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
    learning_rate=1e-3

    batch_size=256
    ema=True

    mnist_train = dataloader.fetch_train_data()

    dataloader_train = torch.utils.data.DataLoader(
        mnist_train,
        batch_size=batch_size,
        shuffle=True
    )

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    # DDPM-style marginal_prob_std handling (exactly like baseline)
    mnist_unet = ScoreNet(lambda t: torch.ones_like(t))

    model = FlowMatching(mnist_unet).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9999)

    avg_epoch_train_time = train(
        model=model,
        optimizer=optimizer,
        scheduler=scheduler,
        dataloader=dataloader_train,
        epochs=epochs,
        device=device,
        ema=ema,
        per_epoch_callback=reporter if use_reporter else None
    )

    # Added metrics computation:
    N = dataloader.get_eval_sample_size()

    ref_train = dataloader.get_eval_train_sample()
    ref_test = dataloader.get_eval_test_sample()

    generation_time, model_samples = generate(model, num_samples = N, run_number = run_number)
    fid_train = FID(X_true = ref_train, X_approx = model_samples)
    fid_test = FID(X_true = ref_test, X_approx = model_samples)
    inception = inception_score(model_samples)


    return avg_epoch_train_time * epochs, generation_time, fid_train, fid_test, inception